{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from feast import FeatureStore, RepoConfig, RegistryConfig\n",
    "import pandas as pd\n",
    "from sqlalchemy import text, create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Define the PostgreSQL connection parameters\n",
    "hostname = 'localhost'\n",
    "port = '5432'\n",
    "database = 'feast'\n",
    "username = 'feast'\n",
    "password = 'feast'\n",
    "\n",
    "# Create a SQLAlchemy engine object\n",
    "engine = create_engine(f'postgresql://{username}:{password}@{hostname}:{port}/{database}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "with engine.connect() as conn:\n",
    "    entity_df = pd.read_sql('titanic_train_target', conn)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId  Survived                  event_timestamp  \\\n0              2         1 2023-03-16 07:07:15.078711+00:00   \n1              4         1 2023-03-16 07:07:15.078711+00:00   \n2              7         0 2023-03-16 07:07:15.078711+00:00   \n3             11         1 2023-03-16 07:07:15.078711+00:00   \n4             12         1 2023-03-16 07:07:15.078711+00:00   \n..           ...       ...                              ...   \n178          872         1 2023-03-16 07:07:15.078711+00:00   \n179          873         0 2023-03-16 07:07:15.078711+00:00   \n180          880         1 2023-03-16 07:07:15.078711+00:00   \n181          888         1 2023-03-16 07:07:15.078711+00:00   \n182          890         1 2023-03-16 07:07:15.078711+00:00   \n\n                       created  \n0   2023-03-16 07:07:15.081927  \n1   2023-03-16 07:07:15.081927  \n2   2023-03-16 07:07:15.081927  \n3   2023-03-16 07:07:15.081927  \n4   2023-03-16 07:07:15.081927  \n..                         ...  \n178 2023-03-16 07:07:15.081927  \n179 2023-03-16 07:07:15.081927  \n180 2023-03-16 07:07:15.081927  \n181 2023-03-16 07:07:15.081927  \n182 2023-03-16 07:07:15.081927  \n\n[183 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>event_timestamp</th>\n      <th>created</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>7</td>\n      <td>0</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>11</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>12</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>872</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>873</td>\n      <td>0</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>880</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>888</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n    <tr>\n      <th>182</th>\n      <td>890</td>\n      <td>1</td>\n      <td>2023-03-16 07:07:15.078711+00:00</td>\n      <td>2023-03-16 07:07:15.081927</td>\n    </tr>\n  </tbody>\n</table>\n<p>183 rows Ã— 4 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entity_df[\"event_timestamp\"] = pd.to_datetime(entity_df[\"event_timestamp\"])\n",
    "\n",
    "entity_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "feature_store = FeatureStore(repo_path=\"titanic_feature/feature_repo\")  # Initialize the feature store\n",
    "#feature_store = FeatureStore(config=repo_config)\n",
    "#feature_store.refresh_registry()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "feature_service = feature_store.get_feature_service(\"titanic_survive_svc_v1\")\n",
    "job = feature_store.get_historical_features(\n",
    "    features=feature_service,\n",
    "    entity_df=entity_df,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "training_df = job.to_df()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Feature schema -----\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183 entries, 0 to 182\n",
      "Data columns (total 15 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   PassengerId      183 non-null    int64         \n",
      " 1   Survived         183 non-null    int64         \n",
      " 2   event_timestamp  183 non-null    datetime64[ns]\n",
      " 3   created          183 non-null    datetime64[ns]\n",
      " 4   PC1              183 non-null    float64       \n",
      " 5   PC2              183 non-null    float64       \n",
      " 6   PC3              183 non-null    float64       \n",
      " 7   PC4              183 non-null    float64       \n",
      " 8   PC5              183 non-null    float64       \n",
      " 9   Pclass           183 non-null    int64         \n",
      " 10  Age              183 non-null    float64       \n",
      " 11  Sex              183 non-null    int64         \n",
      " 12  SibSp            183 non-null    int64         \n",
      " 13  Parch            183 non-null    int64         \n",
      " 14  Fare             183 non-null    float64       \n",
      "dtypes: datetime64[ns](2), float64(7), int64(6)\n",
      "memory usage: 21.6 KB\n",
      "None\n",
      "\n",
      "----- Example features -----\n",
      "\n",
      "   PassengerId  Survived            event_timestamp  \\\n",
      "0            2         1 2023-03-16 07:07:15.078711   \n",
      "1            4         1 2023-03-16 07:07:15.078711   \n",
      "2            7         0 2023-03-16 07:07:15.078711   \n",
      "3           11         1 2023-03-16 07:07:15.078711   \n",
      "4           12         1 2023-03-16 07:07:15.078711   \n",
      "\n",
      "                     created       PC1       PC2       PC3       PC4  \\\n",
      "0 2023-03-16 07:07:15.081927  0.003464 -0.481794 -0.991004 -0.201495   \n",
      "1 2023-03-16 07:07:15.081927 -0.072348 -0.298333 -1.067847 -0.286986   \n",
      "2 2023-03-16 07:07:15.081927 -1.222364 -0.949682  0.258262  0.286256   \n",
      "3 2023-03-16 07:07:15.081927  0.470111  4.075396 -0.779002  0.583059   \n",
      "4 2023-03-16 07:07:15.081927 -1.492001 -1.006702  0.155429  0.534607   \n",
      "\n",
      "        PC5  Pclass   Age  Sex  SibSp  Parch     Fare  \n",
      "0  0.050206       1  38.0    1      1      0  71.2833  \n",
      "1 -0.151978       1  35.0    1      1      0  53.1000  \n",
      "2  0.074684       1  54.0    0      0      0  51.8625  \n",
      "3  0.694532       3   4.0    1      1      1  16.7000  \n",
      "4 -0.089904       1  58.0    1      0      0  26.5500  \n"
     ]
    }
   ],
   "source": [
    "print(\"----- Feature schema -----\\n\")\n",
    "print(training_df.info())\n",
    "\n",
    "print()\n",
    "print(\"----- Example features -----\\n\")\n",
    "print(training_df.head())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from minio import Minio"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "client = Minio(\n",
    "        \"127.0.0.1:9000\",\n",
    "        access_key=\"91v98eLB1zOwDPo8\",\n",
    "        secret_key=\"6ZDwLVoC14AMOVCJozvJtIUjjwZfa0Ma\",\n",
    "        secure=False,\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "<minio.helpers.ObjectWriteResult at 0x7fb96420a9a0>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"titanic_feature/feature_repo/data/titanic_train_final.parquet\"\n",
    "\n",
    "training_df.to_parquet(path)\n",
    "\n",
    "client.fput_object(\n",
    "    \"demo-bucket\", \"titanic_train_final.parquet\", path\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "x = training_df.drop('Survived', axis = 1)\n",
    "y = training_df['Survived']\n",
    "#Split dataset\n",
    "x_train,x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 111)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_561004/489198696.py\", line 1, in <module>\n",
      "    from keras.models import Sequential\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/keras/__init__.py\", line 21, in <module>\n",
      "    from keras import models\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/keras/models/__init__.py\", line 18, in <module>\n",
      "    from keras.engine.functional import Functional\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/keras/engine/functional.py\", line 24, in <module>\n",
      "    import tensorflow.compat.v2 as tf\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.tools import module_util as _module_util\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/python/__init__.py\", line 37, in <module>\n",
      "    from tensorflow.python.eager import context\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/python/eager/context.py\", line 28, in <module>\n",
      "    from tensorflow.core.framework import function_pb2\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/core/framework/function_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/core/framework/attr_value_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/core/framework/tensor_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/core/framework/resource_handle_pb2.py\", line 16, in <module>\n",
      "    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/tensorflow/core/framework/tensor_shape_pb2.py\", line 36, in <module>\n",
      "    _descriptor.FieldDescriptor(\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/google/protobuf/descriptor.py\", line 561, in __new__\n",
      "TypeError: Descriptors cannot not be created directly.\n",
      "If this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\n",
      "If you cannot immediately regenerate your protos, some other possible workarounds are:\n",
      " 1. Downgrade the protobuf package to 3.20.x or lower.\n",
      " 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n",
      "\n",
      "More information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1288, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1177, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1030, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 960, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 870, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 704, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/stack_data/core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/stack_data/utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/stack_data/core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"/home/ubuntu/miniconda3/envs/ml_workflow_3_9/lib/python3.9/site-packages/executing/executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(activation=\"relu\", input_dim=22, units=11, kernel_initializer=\"uniform\"))\n",
    "classifier.add(Dense(activation=\"relu\", units=11, kernel_initializer=\"uniform\"))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(activation=\"relu\", units=11, kernel_initializer=\"uniform\"))\n",
    "classifier.add(Dropout(0.5))\n",
    "classifier.add(Dense(activation=\"relu\", units=5, kernel_initializer=\"uniform\"))\n",
    "classifier.add(Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\"))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "classifier.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_4\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......dropout_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-03-15 13:46:03         3128\n",
      "variables.h5                                   2023-03-15 13:46:03        25808\n",
      "metadata.json                                  2023-03-15 13:46:03           64\n",
      "Keras model archive loading:\n",
      "File Name                                             Modified             Size\n",
      "config.json                                    2023-03-15 13:46:02         3128\n",
      "variables.h5                                   2023-03-15 13:46:02        25808\n",
      "metadata.json                                  2023-03-15 13:46:02           64\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r)>) loading:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_1\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_2\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_3\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dense_4\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......dropout\n",
      ".........vars\n",
      "......dropout_1\n",
      ".........vars\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      "...vars\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "filename = \"titanic_feature/feature_repo/data/titanic_model.joblib\"\n",
    "joblib.dump(classifier, filename)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "data": {
      "text/plain": "<minio.helpers.ObjectWriteResult at 0x7fb7d8fa0520>"
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.fput_object(\n",
    "        \"demo-bucket\",\n",
    "        \"titanic_model.joblib\",\n",
    "        filename\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
